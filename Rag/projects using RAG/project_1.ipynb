{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GROQ_API_KEY']=os.getenv(\"GROQ_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7e9c22107b00>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7e9c22124c50>, model_name='mistral-saba-24b', model_kwargs={}, groq_api_key=SecretStr('**********'), max_tokens=4096)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatGroq(\n",
    "    model_name=\"mistral-saba-24b\",  # Updated to current Groq model name\n",
    "    temperature=0.7,\n",
    "    max_tokens=4096,\n",
    " \n",
    ")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Aryaman! Nice to meet you. How can I assist you today? If you're in the field of AI, we can discuss anything from machine learning algorithms to AI ethics, or even some of the latest trends in the industry. What's on your mind?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "result=llm.invoke([HumanMessage(content=\"Hi .My name is Aryaman, I am an AI engineer\")])\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You've introduced yourself as Aryaman, and you mentioned that you are an AI engineer. Is there something specific you would like to talk about or learn more about in the field of AI?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "res=llm.invoke([\n",
    "    HumanMessage(content=\"Hi .My name is Aryaman, I am an AI engineer\"),\n",
    "    AIMessage(content=\"Hello Aryaman! Nice to meet you. How can I assist you today? If you're in the field of AI, we can discuss anything from machine learning algorithms to AI ethics, or even some of the latest trends in the industry. What's on your mind?\"),\n",
    "    HumanMessage(content=\"Hey,what's my name and what do I do?\")\n",
    "    ])\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
       "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]), kwargs={}, config={}, config_factories=[], get_session_history=<function get_session at 0x7e9c21e66ac0>, history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## message history\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "#to know that different session we are buliding a function\n",
    "\n",
    "store={}# define store as dict\n",
    "\n",
    "def get_session(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(llm,get_session)\n",
    "with_message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Aryaman! It's nice to meet you. As an AI engineer, you're likely involved in creating and refining AI systems. Here are a few things we could discuss or work on:\n",
      "\n",
      "1. **Project Ideas**: I can help brainstorm project ideas that align with your interests and skills.\n",
      "2. **Technical Guidance**: If you're working on a specific problem, I can provide technical guidance or suggest relevant resources.\n",
      "3. **Algorithm Explanations**: I can help explain how certain algorithms work or suggest appropriate algorithms for specific tasks.\n",
      "4. **Best Practices**: We can discuss best practices in AI development, such as model evaluation, bias mitigation, or ethical considerations.\n",
      "5. **Learning Resources**: If you're looking to expand your knowledge, I can recommend books, online courses, or research papers.\n",
      "6. **Code Review**: If you're comfortable sharing code snippets, I can provide feedback and suggestions for improvement.\n",
      "\n",
      "What would you like to focus on?\n"
     ]
    }
   ],
   "source": [
    "resi=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi my name is Aryaman and I am an AI engineer\")],\n",
    "    config=config\n",
    ")\n",
    "print(resi.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Aryaman, and your occupation is an AI engineer.\n"
     ]
    }
   ],
   "source": [
    "resp=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"tell my name and what is my occupation?\")],\n",
    "    config=config\n",
    ")\n",
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change -->the session id\n",
    "config_1={\"configurable\":{\"session_id\":\"chat2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm an assistant that operates on the information I've been trained on up until 2023, so I don't have real-time knowledge or personal experiences. I don't know your name. If you'd like, you can tell me your name and I can use it during our conversation. How about you? What's your name?\n"
     ]
    }
   ],
   "source": [
    "resp=with_message_history.invoke(\n",
    "    \n",
    "        [HumanMessage(content=\"tell my name\")],\n",
    "        config=config_1\n",
    "    \n",
    ")\n",
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Aryaman! Nice to meet you. How are you today?\n"
     ]
    }
   ],
   "source": [
    "resp=with_message_history.invoke(\n",
    "    \n",
    "        [HumanMessage(content=\"hey my name is Aryaman\")],\n",
    "        config=config_1\n",
    "    \n",
    ")\n",
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Template\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['messages'], input_types={'messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7e9c22850680>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='you are helpful assisant .Answer all the question to the best of your ablity'), additional_kwargs={}), MessagesPlaceholder(variable_name='messages')])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7e9c22107b00>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7e9c22124c50>, model_name='mistral-saba-24b', model_kwargs={}, groq_api_key=SecretStr('**********'), max_tokens=4096)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "        \"system\",\"you are helpful assisant .Answer all the question to the best of your ablity\",\n",
    "),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    "    \n",
    ")\n",
    "chain=prompt|llm\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Aryaman! Nice to meet you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "res_1=chain.invoke({\"messages\":[HumanMessage(content=\"Hi my name is Aryaman\")]})\n",
    "print(res_1.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session)\n",
    "\n",
    "config_2={\"configurable\":{\"session_id\":\"chat3\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Aryaman! It's nice to meet you. I'm here to help with any questions or tasks you have. Here are a few things I can do:\\n\\n1. **Answer Questions**: I can provide information based on the data I've been trained on (up to 2021).\\n2. **Explain Concepts**: I can help explain complex ideas in a simpler way.\\n3. **Provide Suggestions**: Whether it's a book to read, a movie to watch, or a recipe to cook, I can provide recommendations.\\n4. **Help with Language**: I can help with language translation in multiple languages, define words, or provide synonyms/antonyms.\\n5. **Perform Simple Tasks**: I can do simple calculations, conversions, or other basic tasks.\\n\\nWhat would you like help with today?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 171, 'prompt_tokens': 28, 'total_tokens': 199, 'completion_time': 0.518181818, 'prompt_time': 0.002543717, 'queue_time': 0.099414714, 'total_time': 0.520725535}, 'model_name': 'mistral-saba-24b', 'system_fingerprint': 'fp_07e680a590', 'finish_reason': 'stop', 'logprobs': None}, id='run-eb6b750d-a2a9-4fe1-bc7a-43dcd5cf1e2e-0', usage_metadata={'input_tokens': 28, 'output_tokens': 171, 'total_tokens': 199})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi my name is Aryaman\")],\n",
    "    config=config_2\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['language', 'messages'], input_types={'messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7e9c22850680>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='You are a helpful assistant.Answer all the question to the best of your ablity in {language}'), additional_kwargs={}), MessagesPlaceholder(variable_name='messages')])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7e9c22107b00>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7e9c22124c50>, model_name='mistral-saba-24b', model_kwargs={}, groq_api_key=SecretStr('**********'), max_tokens=4096)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## add more complexity\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "(\n",
    "    \"system\",\"You are a helpful assistant.Answer all the question to the best of your ablity in {language}\"\n",
    "),\n",
    "MessagesPlaceholder(variable_name=\"messages\")\n",
    "\n",
    "    ]\n",
    ")\n",
    "chain=prompt|llm\n",
    "chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते, आर्यमन! आपसे मिलकर खुशी हुई। मैं आपकी कैसे मदद कर सकता हूँ?'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({\"messages\":[HumanMessage(content=\"Hi my name is Aryaman\")],\"language\":\"Hindi\"})\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते आर्यमन तिवारी! मैं आपकी मदद करने के लिए यहाँ हूँ। आप मुझे किसी भी सवाल पूछ सकते हैं, और मैं अपनी पूरी क्षमता से उसका उत्तर देने की कोशिश करूंगा।\\n\\nचूंकि मुझे आपके पेशे या काम के बारे में जानकारी नहीं है, इसलिए मैं आपसे यह पूछना चाहता हूँ कि आप क्या करते हैं? अगर आप मुझे बताएं, तो मैं आपको बेहतर ढंग से सहायता कर सकता हूँ।\\n\\nअगर आपको कोई और सवाल है या मदद की जरूरत है, तो बेझिजक पूछें। मैं आपकी मदद करने के लिए यहाँ हूँ!'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_3={\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "\n",
    "response=with_message_history.invoke(\n",
    "    {'messages':[HumanMessage(content=\"Hi, I Am Aryaman Tiwari\")],\"language\":\"Hindi\"},\n",
    "    config=config_3\n",
    "    \n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते आर्यमन तिवारी!\\n\\nचूंकि आपने मुझसे कहा है कि आप आर्यमन तिवारी हैं, इसलिए मुझे पता है कि आपका नाम आर्यमन तिवारी है। आपके पेशे या काम के बारे में मुझे कोई जानकारी नहीं है। अगर आप मुझे अपने पेशे या काम के बारे में बताना चाहें, तो मैं आपकी मदद कर सकता हूँ।\\n\\nअगर आपके पास कोई और सवाल है या किसी भी विषय पर मदद चाहिए, तो कृपया मुझे बताएं। मैं आपकी मदद करने के लिए यहाँ हूँ!'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    {'messages':[HumanMessage(content=\"What is my name and what work I do?\")],\"language\":\"Hindi\"},\n",
    "    config=config_3\n",
    "    \n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage the Conversation History\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='youre a good assitant', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hi I m AT', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='hi', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla Icecream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is 2+2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Thanks', additional_kwargs={}, response_metadata={}),\n",
       " SystemMessage(content='having fun', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=70,\n",
    "    strategy=\"last\",\n",
    "    token_counter=llm,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    "    \n",
    "    \n",
    ")\n",
    "messages=[\n",
    "    SystemMessage(content=\"youre a good assitant\"),\n",
    "    HumanMessage(content=\"hi I m AT\"),\n",
    "    AIMessage(content=\"hi\"),\n",
    "    HumanMessage(content=\"I like vanilla Icecream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"what is 2+2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    AIMessage(content=\"Thanks\"),\n",
    "    SystemMessage(content=\"having fun\"),\n",
    "    AIMessage(content=\"yes!\")\n",
    "]\n",
    "res=trimmer.invoke(messages)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on our conversation, you mentioned that you like vanilla ice cream.'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "response=chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"What ice cream do I like\")],\n",
    "    \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets wrap this in the message history\n",
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,get_session,input_messages_key=\"messages\"\n",
    "    \n",
    ")\n",
    "config_5={\"configurable\":{\"session_id\":\"chat5\"}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You said you like vanilla ice cream! Is there a specific flavor or brand that you enjoy the most?'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"What ice cream do I like\")],\n",
    "    \"language\":\"English\"\n",
    "    },\n",
    "    config=config_5\n",
    ")\n",
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
